import json
import traceback
from typing import AsyncGenerator, Optional, Dict, Any
from langgraph.types import Command
from langfuse.langchain import CallbackHandler

# å¯¼å…¥è·å–å›¾çš„æ–¹æ³•
from ..infrastructure.agents.orchestrator_agent import get_orchestrator_graph
from ..domain.interfaces import AgentService
from ..domain.models import ReportRequest
from ..infrastructure.langfuse.factory import init_langfuse_client
from ..core.config import settings

class AgentServiceImpl(AgentService):
    def __init__(self):
        # åˆå§‹åŒ–å›¾å®ä¾‹
        self.graph = get_orchestrator_graph()

    async def generate_report(self, request: ReportRequest) -> AsyncGenerator[str, None]:
        """
        å®ç° generate_report æ¥å£ã€‚
        æ ¹æ® request.action å†³å®šæ˜¯å¯åŠ¨æ–°ä»»åŠ¡è¿˜æ˜¯æ¢å¤ä¸­æ–­çš„ä»»åŠ¡ã€‚
        """
        thread_id = request.report_id
        input_data = None
        resume_command = None

        # 1. æ„å»ºè¾“å…¥å‚æ•°
        if request.action == "start":
            if not request.query:
                # å¦‚æœæ˜¯å¼€å§‹è¯·æ±‚ï¼Œå¿…é¡»è¦æœ‰ query
                yield f"event: error\ndata: {json.dumps({'error': 'Start action requires a query'})}\n\n"
                return

            input_data = {
                "goal": request.query,
                "plan": [],
                "results": [],
                "loop_count": 0,
                "user_feedback": None,
                "reflection_feedback": None,
                "final_report": ""
            }
        
        elif request.action == "approve":
            resume_command = Command(resume={"action": "approve"})
            
        elif request.action == "revise":
            resume_command = Command(resume={"action": "revise", "feedback": request.feedback})

        # 2. è°ƒç”¨æ ¸å¿ƒæµç”Ÿæˆé€»è¾‘
        # å¤ç”¨åŸ event_stream_generator çš„é€»è¾‘ï¼Œä½†ç°åœ¨å®ƒæ˜¯å†…éƒ¨å®ç°ç»†èŠ‚
        async for event in self._run_graph_stream(thread_id, input_data, resume_command):
            yield event

    async def _run_graph_stream(
        self, 
        thread_id: str, 
        input_data: Optional[Dict[str, Any]] = None, 
        resume_command: Optional[Command] = None
    ) -> AsyncGenerator[str, None]:
        """
        å†…éƒ¨æ–¹æ³•ï¼šæ‰§è¡Œ Graph å¹¶ç”Ÿæˆ SSE æ ¼å¼çš„æµã€‚
        """
        
        # --- ğŸŸ¢ ä¿®æ”¹å¼€å§‹ï¼šLangfuse è¿è¡ŒçŠ¶æ€æ£€æµ‹ ---
        langfuse = None
        callbacks = []
        
        try:
            # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = init_langfuse_client(
                public_key=settings.langfuse.public_key,
                secret_key=settings.langfuse.secret_key,
                base_url=settings.langfuse.base_url
            )
            
            # 2. ã€å…³é”®æ­¥éª¤ã€‘æ‰§è¡Œè¿æ¥æ£€æŸ¥
            # auth_check() ä¼šå‘èµ·ä¸€ä¸ªè½»é‡çº§è¯·æ±‚éªŒè¯å‡­è¯å’Œè¿æ¥
            # å¦‚æœè¿æ¥è¢«æ‹’ç»(Connection Refused)ï¼Œè¿™é‡Œä¼šæŠ›å‡ºå¼‚å¸¸æˆ–è¿”å› False
            if client and client.auth_check():
                langfuse = client
                # åªæœ‰æ£€æŸ¥é€šè¿‡ï¼Œæ‰åˆå§‹åŒ– Handler å¹¶åŠ å…¥å›è°ƒåˆ—è¡¨
                langfuse_handler = CallbackHandler()
                callbacks.append(langfuse_handler)
            else:
                print("[Langfuse] âš ï¸ Auth check failed or service down. Tracing skipped.")
                
        except Exception as e:
            # æ•è·æ‰€æœ‰è¿æ¥é”™è¯¯ï¼Œé˜²æ­¢åº”ç”¨å´©æºƒ
            print(f"[Langfuse] âš ï¸ Connection check failed: {e}. Tracing skipped.")
            langfuse = None
        # --- ğŸŸ¢ ä¿®æ”¹ç»“æŸ ---

        config = {
            "configurable": {"thread_id": thread_id}, 
            "callbacks": callbacks, # ä½¿ç”¨åŠ¨æ€ç”Ÿæˆçš„ callbacks åˆ—è¡¨
            "metadata": {
                # å³ä½¿æ²¡å¼€å¯ Traceï¼Œä¿ç•™ metadata ä¹Ÿä¸å½±å“è¿è¡Œ
                "langfuse_session_id": thread_id,  
                "thread_id": thread_id             
            }
        }

        try:
            # å†³å®šæ˜¯å¯åŠ¨æ–°ä»»åŠ¡è¿˜æ˜¯æ¢å¤ä¸­æ–­
            if resume_command:
                async_generator = self.graph.astream_events(resume_command, config, version="v2")
            else:
                async_generator = self.graph.astream_events(input_data, config, version="v2")

            async for event in async_generator:
                kind = event["event"]
                
                # 1. å¤„ç† LLM æµå¼è¾“å‡º (Writer èŠ‚ç‚¹)
                if kind == "on_chat_model_stream" and event["metadata"].get("langgraph_node") == "writer":
                    chunk = event["data"]["chunk"]
                    if chunk.content:
                        yield f"event: report_token\ndata: {json.dumps({'token': chunk.content})}\n\n"

                # 2. å¤„ç†é€šç”¨æ—¥å¿—äº‹ä»¶ (Agent Log)
                elif kind == "on_custom_event" and event["name"] == "agent_log":
                    yield f"event: log\ndata: {json.dumps(event['data'])}\n\n"
                
                # 3. å¤„ç† Worker è¿›åº¦äº‹ä»¶
                elif kind == "on_custom_event" and event["name"] == "worker_progress":
                    yield f"event: progress\ndata: {json.dumps(event['data'])}\n\n"

            # å¾ªç¯ç»“æŸï¼Œæ£€æŸ¥æœ€ç»ˆçŠ¶æ€æˆ–ä¸­æ–­
            snapshot = await self.graph.aget_state(config)
            
            # Debug log
            print(f"Snapshot next: {snapshot.next}")
            
            if snapshot.next:
                # å°è¯•æå–ä¸­æ–­ä¿¡æ¯
                interrupt_value = None
                if snapshot.tasks:
                    for task in snapshot.tasks:
                        if task.interrupts:
                            interrupt_value = task.interrupts[0].value
                            break
                
                if interrupt_value:
                    yield f"event: interrupt\ndata: {json.dumps(interrupt_value)}\n\n"
                else:
                    # å¼‚å¸¸ä¸­æ–­çŠ¶æ€ï¼šæœ‰ next ä½†æ—  interrupt ä¿¡æ¯
                    yield f"event: log\ndata: {json.dumps({'message': 'âš ï¸ ç³»ç»Ÿæš‚åœï¼Œä½†æœªæ£€æµ‹åˆ°æ˜ç¡®çš„ä¸­æ–­ä¿¡å·ï¼Œè¯·æ£€æŸ¥åç«¯æ—¥å¿—ã€‚'})}\n\n"
            else:
                # ä»»åŠ¡å®Œæˆ
                final_report = snapshot.values.get("final_report")
                if final_report:
                    yield f"event: done\ndata: {json.dumps({'report': final_report})}\n\n"
                else:
                    pass

        except Exception as e:
            print(f"Stream Error: {e}")
            traceback.print_exc()
            yield f"event: error\ndata: {json.dumps({'error': str(e)})}\n\n"

        finally:
            # --- ğŸŸ¢ ä¿®æ”¹ï¼šFlush æ—¶å¢åŠ åˆ¤ç©ºé€»è¾‘ ---
            try:
                # åªæœ‰å½“ langfuse å®ä¾‹æˆåŠŸåˆ›å»ºä¸”æ£€æŸ¥é€šè¿‡æ—¶ï¼Œæ‰å°è¯• flush
                if langfuse:
                    langfuse.flush()
            except Exception as e:
                # å¦‚æœæ—¥å¿—å‘é€å¤±è´¥ï¼ˆæ¯”å¦‚æ–­ç½‘ï¼‰ï¼Œåªæ‰“å°é”™è¯¯ï¼Œä¸è¦å½±å“ä¸šåŠ¡çš„ä¸»æµç¨‹
                print(f"[Langfuse] Flush failed: {e}")